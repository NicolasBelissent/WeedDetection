{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"csic_64_finetuned_on_deepweeds.ipynb","provenance":[],"authorship_tag":"ABX9TyPdOKffSy9mDp0+evZosPIW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"5sId94n5eBSu","executionInfo":{"status":"ok","timestamp":1658416183110,"user_tz":-60,"elapsed":335,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","import helper\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import classification_report,accuracy_score\n","from google.colab import files\n","from torchsummary import summary\n","# import onnx\n","# from onnx2pytorch import ConvertModel\n","from tqdm import trange\n","from tqdm import tqdm\n","import h5py"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIQA_n2NfCX4","executionInfo":{"status":"ok","timestamp":1658414979509,"user_tz":-60,"elapsed":36423,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}},"outputId":"0ac62927-51fb-4ee8-b145-ba00c812772e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["links to fine tuned models:\n","\n","\n","*   http://ptak.felk.cvut.cz/personal/sulcmila/models/LifeCLEF2018/\n","\n","*   http://ptak.felk.cvut.cz/personal/sulcmila/models/LifeCLEF2019/\n","\n","*   www.leafnet.pbarre.de \n","\n","*   https://www.kaggle.com/datasets/maksymshkliarevskyi/cassava-leaf-disease-models?select=EfNetB0_275_16.h5\n","\n"],"metadata":{"id":"sFgnvrv9n4DZ"}},{"cell_type":"code","source":["path_to_model = 'drive/MyDrive/trained_models/resnet.hdf5'\n","#path_to_model = 'drive/MyDrive/trained_models/deepweeds_resnet50_pretrained'\n","feature_extract = True"],"metadata":{"id":"yrT7Ka1BfD4f","executionInfo":{"status":"ok","timestamp":1658415091645,"user_tz":-60,"elapsed":5,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","h5 = h5py.File(path_to_model, 'r')\n","\n","# build model to map pretrained deepweeds model\n","model = models.resnet50()\n","set_parameter_requires_grad(model, True)\n","model.fc = nn.Linear(2048, 9)\n","model.load_state_dict(h5, strict=False)\n","\n","# change output later to map csic data\n","model.fc = nn.Linear(2048, 4)\n"],"metadata":{"id":"cBJLIjVffyWw","executionInfo":{"status":"ok","timestamp":1658416206845,"user_tz":-60,"elapsed":1290,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deN274IvGJLf","executionInfo":{"status":"ok","timestamp":1658416215015,"user_tz":-60,"elapsed":204,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}},"outputId":"dfb80e07-1861-41c4-ee6b-5f2389ee4632"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["# onnx_model = onnx.load(path_to_model)\n","# onnx.checker.check_model(onnx_model)\n","# pytorch_model = ConvertModel(onnx_model , experimental = True)"],"metadata":{"id":"GuxHM1jTf1u-","executionInfo":{"status":"ok","timestamp":1658416216164,"user_tz":-60,"elapsed":2,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"czGmdTR1f7BP","executionInfo":{"status":"ok","timestamp":1658416220710,"user_tz":-60,"elapsed":4288,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"WxD5UUT6iO0R","executionInfo":{"status":"ok","timestamp":1658416220710,"user_tz":-60,"elapsed":5,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# build dataloader\n","mean = torch.tensor([135.31470632, 124.53849418, 103.39646082])\n","std = torch.tensor([5.18153318, 4.14170719, 5.17011963])\n","\n","transform = transforms.Compose([transforms.Resize(255),\n","                                transforms.CenterCrop(224),\n","                                transforms.ToTensor(),\n","                                transforms.RandomRotation(degrees=360),\n","                                transforms.RandomHorizontalFlip(p=0.5),\n","                                transforms.ColorJitter(brightness=.5, hue=.3),\n","                                transforms.RandomInvert(),\n","                                transforms.Normalize(mean, std)])\n","\n","# transform = transforms.Compose([transforms.Resize(255),\n","#                                 transforms.CenterCrop(224),\n","#                                 transforms.ToTensor(),\n","#                                 transforms.Normalize(mean, std)])\n","\n","balanced_path_data = 'drive/MyDrive/balanced_csic_data_64/training'\n","\n","\n","def train_val_dataset(dataset, val_split=0.1):\n","    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n","    datasets = {}\n","    datasets['train'] = Subset(dataset, train_idx)\n","    datasets['val'] = Subset(dataset, val_idx)\n","    return datasets\n","\n","# load the balanced dataset\n","balanced_dataset = datasets.ImageFolder(balanced_path_data, transform=transform)\n","balanced_datasets = train_val_dataset(balanced_dataset)\n","\n","\n","class_dict = balanced_dataset.class_to_idx"],"metadata":{"id":"3PX3C9GLjWG4","executionInfo":{"status":"ok","timestamp":1658416231878,"user_tz":-60,"elapsed":11171,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","balanced_dataloaders_dict = {x: torch.utils.data.DataLoader(balanced_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2) for x in ['train', 'val']}"],"metadata":{"id":"o8WbRr3wjWJH","executionInfo":{"status":"ok","timestamp":1658416231879,"user_tz":-60,"elapsed":19,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=20, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","    train_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            with tqdm(dataloaders[phase],unit = 'batch') as tepoch:\n","              # Iterate over data.\n","              for inputs, labels in tepoch:\n","                  inputs = inputs.to(device)\n","                  labels = labels.to(device)\n","\n","                  # zero the parameter gradients\n","                  optimizer.zero_grad()\n","\n","                  # forward\n","                  # track history if only in train\n","                  with torch.set_grad_enabled(phase == 'train'):\n","                      # Get model outputs and calculate loss\n","                      # Special case for inception because in training it has an auxiliary output. In train\n","                      #   mode we calculate the loss by summing the final output and the auxiliary output\n","                      #   but in testing we only consider the final output.\n","                      if is_inception and phase == 'train':\n","                          # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                          outputs, aux_outputs = model(inputs)\n","                          loss1 = criterion(outputs, labels)\n","                          loss2 = criterion(aux_outputs, labels)\n","                          loss = loss1 + 0.4*loss2\n","                      else:\n","                          outputs = model(inputs)\n","                          loss = criterion(outputs, labels)\n","\n","                      _, preds = torch.max(outputs, 1)\n","                      \n","\n","                      # backward + optimize only if in training phase\n","                      if phase == 'train':\n","                          loss.backward()\n","                          optimizer.step()\n","\n","                  # statistics\n","                  running_loss += loss.item() * inputs.size(0)\n","                  #getCategoricalAccuracy(preds, labels.data, class_dict)\n","                  running_corrects += torch.sum(preds == labels.data)\n","\n","              epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","              epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","              print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","              # deep copy the model\n","              if phase == 'val' and epoch_acc > best_acc:\n","                  best_acc = epoch_acc\n","                  best_model_wts = copy.deepcopy(model.state_dict())\n","              if phase == 'val':\n","                  val_acc_history.append(epoch_acc)\n","              if phase == 'train':\n","                  train_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history, train_acc_history"],"metadata":{"id":"VKjiNDbEiP2X","executionInfo":{"status":"ok","timestamp":1658416231879,"user_tz":-60,"elapsed":18,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.Adam(params_to_update, lr=1e-4)\n","\n","# Setup the loss fxn\n","import time\n","import copy\n","criterion = nn.CrossEntropyLoss()\n","epoch = 100\n","\n","# Training a pretrained Resnet18 on a balanced dataset\n","pytorch_model, balanced_val_hist, balanced_tr_hist  = train_model(model, balanced_dataloaders_dict, criterion, optimizer_ft,num_epochs= epoch)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNd41j2Ti7_p","outputId":"f510c37d-71ef-46c5-cb42-b6b7bea4e988"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 96%|█████████▌| 90/94 [00:38<00:01,  2.29batch/s]"]}]},{"cell_type":"code","source":["b_train_acc = []\n","for val in balanced_tr_hist:\n","  b_train_acc.append(val.cpu().data.numpy())\n","\n","b_val_acc = []\n","for val in balanced_val_hist:\n","  b_val_acc.append(val.cpu().data.numpy())\n","\n","plt.plot(b_val_acc, 'm-', label='Finetuned Resnet50 Validation accuracy')\n","plt.plot(b_train_acc,'m--', label='Finetuned Resnet50 Training accuracy')\n","plt.legend()\n","plt.savefig('64_100epochs_finetuned.png')\n","plt.show()\n","files.download('64_100epochs_finetuned.png')"],"metadata":{"id":"bqpyGKM6j2oI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_path_data = 'drive/MyDrive/balanced_csic_data_64/testing'\n","testing_dataset = torchvision.datasets.ImageFolder(test_path_data, transform=transform)\n","batch_size = 32\n","testing_dataloader =torch.utils.data.DataLoader(testing_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","print(testing_dataset.class_to_idx)"],"metadata":{"id":"Rowkny7SKUQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# send model to GPU\n","if torch.cuda.is_available():\n","    model.cuda()"],"metadata":{"id":"JFqrjdbRKXgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getTestingMetrics(dataloader, model):\n","  # send model to GPU\n","  if torch.cuda.is_available():\n","    model.cuda()\n","\n","  # with tqdm(testing_dataloader) as tepoch:\n","  lbs = []\n","  preds = []\n","  #   # Iterate over data.\n","  for inputs, labels in dataloader:\n","    test_inputs = inputs.to(device)\n","    #test_labels = labels.to(device)\n","    outputs = model(test_inputs)\n","    _, pred = torch.max(outputs, 1)\n","    lbs+=(list(labels.numpy()))\n","    preds+= list(pred.cpu().data.numpy())\n","  print('Overall testing accuracy:',accuracy_score(lbs, preds))\n","  print(classification_report(lbs, preds, target_names=class_dict.keys()))\n"],"metadata":{"id":"QXbVQFjEKZKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["getTestingMetrics(testing_dataloader, model)"],"metadata":{"id":"tNgorI90Kh7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    accuracy                           0.78       850\n","   macro avg       0.70      0.55      0.57       850\n","weighted avg       0.79      0.78      0.76       850\n"],"metadata":{"id":"Mjw24hMVKngw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"3Oi4l-pGm-7V","executionInfo":{"status":"aborted","timestamp":1658414980319,"user_tz":-60,"elapsed":31,"user":{"displayName":"Nicolas Belissent","userId":"02829269761105174140"}}},"execution_count":null,"outputs":[]}]}